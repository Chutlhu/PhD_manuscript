\chapter{\library{Blaster}: Knowledge-driven Acoustic Echo Retrieval}\label{ch:blaster}
\openepigraph{
    My beautiful astronaut//
    With an impulsive world//
    A twisted scientist!}{Venetian Snares, \textit{1000 Years}}

\vspace{-2.5em}
\newthought{Synopsis} \marginpar{%
\footnotesize
\textbf{Keywords:} Blind Channel Identification, Super Resolution, Sparsity, Acoustic Impulse Response.
\\\textbf{Resources:}
\begin{itemize}
    \item \href{https://doi.org/10.1109/ICASSP40776.2020.9054647}{Paper}
    \item \href{https://gitlab.inria.fr/panama-team/blaster}{Code}
    \item \href{https://hal.archives-ouvertes.fr/hal-02469901}{Open-access paper with supplementary material}
    \item \href{https://sigport.org/documents/blaster-grid-method-blind-and-regularized-acoustic-echoes-retrieval}{Slides}
    \item \href{https://youtu.be/rPaqZJIfpKo}{Presentation}
\end{itemize}
} \synopsisChBlaster

\mynewline
The material presented in this chapter was previously published in~\cite{di2020blaster} and results from a collaboration with my colleague Clement Elvira whose domain of expertise is in the \CDdef/ framework, while my expertise lies in the audio and acoustic signal processing and modeling aspects.
The section dedicated on the presentation of the \CD/ framework applied to \AER/ is extracted from the related publication and it is written with the help of my colleague.
Here we briefly commented and expanded it and some attention is paid in highlighting the motivation behind it.
Finally, this chapter recalls the main findings of the paper, while bringing additional insights in the existing models for \AER/.

\section{Introduction}
\label{sec:blaster:intro}
% %Striking introducing sentence
% As deeply discussed so far, the temporal structure of the \RIRdef/ plays a central role in room acoustics and audio signal processing.
% % First echo is noise
% It is the result of multiple (indirect) sound propagation paths due to specular and diffuse reflections on the room's surfaces, leading to reverberation~\citeonly{Wang2011}.
% In such conditions, the perceived sound quality is often considered degraded and it is common to observe a detrimental decrease of performance as reverberation increases for applications such as speech recognition~\citeonly{Yoshoka2012} or music information retrieval~\citeonly{Barthet2010}.
% % or music virtual reality~\citeonly{DeMan2017}. %to observe a detrimental decrease of performances with reverberation. as well as music virtual reality~\citeonly{DeMan2017}.

% % Second echo is information
% On the other hand, RIRs contain very rich geometrical information about the acoustic scene.
% %which is independent from the source signal itself.
% %In contrast with well-consolidated methods,
% Recent \textit{echo-aware} works have shown that the knowledge of the timing of early reflections may boost performance in many audio signal processing applications,
% from dereverberation~\citeonly{Wu2006,Lin2008} to sound localization~\citeonly{ribeiro2010,DiCarlo2019} and separation~\citeonly{Dokmanic2015a, Scheibler2017}.
% Moreover, it allows joint estimation of the receivers' positions~\citeonly{Salvati2016}, the reflective surfaces~\citeonly{Antonacci2012} and consequently the geometry of the room~\citeonly{Dokmanic2013, crocco2017uncalibrated}.
% % or acoustic impedance of surfaces~\citeonly{Antonello2014, Bertin2016}.
% % beamforming \citeonly{dokmanic2015raking},
% % such as for speech enhancement \citeonly{Wu2006}, source localization \citeonly{ribeiro2010}, source separation \citeonly{Scheibler2017} and dereverberation \citeonly{Lin2009}
% % which are common pre-processing steps for many applications \citeonly{Gannot2017}

% \AERdef/ consists in estimating the properties of the early (strong) acoustic reflections only in multi-path environments, and sometimes referred to as time delay estimation~\citeonly{chen2006time}.
Let us recall from~\cref{ch:estimation} some knowledge-based methods addressing \AER/.
Some existing methods rely on a known source signal~\citeonly{park2017compressive,jensen2019method}.
In contrast, when multiple receivers attend an unknown single source, \AER/ can be seen as an instance of \SIMOdef/ \BCEdef/ problem, \ie/ estimating the filters entailing an unknown input and an observed output of a system.
A common approach for solving \AER/ in the context of \SIMO/-\BCE/ is to first blindly estimate a discrete version of the acoustic channels using the so-called cross-relation identity~\citeonly{xu1995least, crocco2016estimation}.
The location of the echoes are then chosen among the strongest peaks with ad-hoc peak-picking techniques.
Such methods are generally \emph{on-grid} in the sense that the estimation relies on a fixed grid of time samples and \textit{a priori} chosen filter lengths.
However, in practice, the true timings of echoes rarely match the sampling grid, thus leading to pathological issues called basis-mismatch in the field of compressed sensing.
To circumvent this issue, the authors of~\citeonly{tukuljac2018mulan} proposed to leverage the framework of finite-rate-of-innovation sampling to make one step towards off-grid approaches.
Despite promising results in the absence of noise and with synthetic data, the quality of the estimation highly relies on the choice of a good initialization point.

\mynewline
Of particular interest in the proposed approach is the recently proposed framework of \CDdef/~\citeonly{candes2014towards}.
By formulating an inverse problem as the recovery of a discrete measure over some parameter space, \CD/ has allowed to overcome imaging device limitations in many applications such as super-resolution~\citeonly{candes2014towards} or PALM/STORM imaging~\citeonly{denoyelle2019sliding}.
In this work, we formulate the problem of \AER/ for stereophonic mixtures, \ie/ using only one microphone pair, within the framework of continuous dictionaries.
The resulting optimization problem is convex and thus not prone to spurious minimizers.
The proposed method is coined \emph{\BLASTERdef/} and requires no parameter tuning.
The method is compared to state-of-the art on-grid approaches under various noise and reverberation levels using simulated data.


\section{Signal model}
We consider here the common setup of stereophonic mixtures, that is 2-channel microphone recordings.
Using the notation presented~\cref{ch:processing}, the continuous-time signal recorded at microphone $\idxMic\in\{1,2\}$ reads
\begin{equation}
    \label{eq:blaster:recordedSignal}
    \tilde{\mic}_i(t) = (\tilde{\src} \convCont \tilde{\flt}_i^\star)(t) + \tilde{\nse}_i(t)
\end{equation}
where $\convCont$ denotes the (continuous) convolution operator, $\tilde{n}_i$ models some additive noise in the measurement process and $\tilde{\flt}_i^\star$ denotes the \RIRdef/.
In the remainder of this chapter, the superscript $\star$ refers to the requested \ac{RIR}.
Assuming the echo model, the \acp{RIR} read
\begin{equation}
    \label{eq:blaster:def_filter_star}
    \tilde{\flt}_i^\star(t) = \sum_{\idxEch=0}^{\numEchs_i} \alpha_i^{(r)} \delta(t - \tau_i^{(r)}) + \tilde{\varepsilon}_i(t)
\end{equation}
where $\numEchs_i$ is the (unknown) number of echoes.
\\In the noiseless case, that is when $\tilde{\nse}_i = 0$ for $i\in\{1,2\}$, we have the cross-relation identity
\begin{equation} \label{eq:blaster:cross-relation}
    \tilde{\mic}_1 \convCont \tilde{\flt}_2^\star = \tilde{\mic}_2 \convCont \tilde{\flt}_1^\star
\end{equation}
by commutativity of the convolution operator.
\\However, in practice, only sampled versions of the two recorded signals are available.
More precisely, we consider the measurement model introduced in~\cref{ch:processing}:
the incoming signal undergoes a (ideal) low-pass filter $\lowpassfilter$ with frequency support $\kintervcc{\sfrac{-\Fs}{2}}{\sfrac{\Fs}{2}}$ before being regularly sampled at the rate $\Fs$.
We denote $\disRecordedSignal_1,\disRecordedSignal_2\in\bbR^{2N}$ the two vectors of $2N$ (consecutive) samples and $i\in\{1, 2\}$ by
\begin{equation}
    \label{eq:blaster:measurement-process}
    \disRecordedSignal_i[n] =
    \kparen{\idealLowPassFilter \convDis \contRecordedSignal}\kparen{\frac{n}{\Fs}}
    \qquad
    \forall n \in\{0, \dots, 2N-1\}
    .
\end{equation}

\section{Background on on-grid blind channel estimation}\label{sec:blaster:background}
We now select and elaborate more on some of the methods mentioned in~\cref{subsec:estimation:bce} concerning optimization approaches for \FIR/-\SIMO/-\BCE/.
Therefore, the following methods operate on discrete-time signal, which are denoted without the tilde according to the notation presented in~\cref{ch:processing}.
Starting from the identity \cref{eq:blaster:cross-relation}, the common \SIMO/-\BCE/ cross-relation framework aims to compute $\contFilter_1, \contFilter_2$ solving the following problem in the discrete-time domain~\citeonly{lin2007blind}:
\begin{equation}
    \label{eq:blaster:xrel_toepl}
    \disFilterHat_1, \disFilterHat_2
    =
    \kargmin_{\disFilter_1, \disFilter_2}
    \;
    \tfrac{1}{2}
    \kvvbar{
        \scrT(\disRecordedSignal_1) \disFilter_2
        -
        \scrT(\disRecordedSignal_2) \disFilter_1
    }_2^2
    +
    \lambda
    \kvvbar{
        \bfh
    }_1
\end{equation}
where
\begin{itemize}
    \item  $\disRecordedSignal_i$ and $\disFilter_i$ are the discrete, sampled version of $\contRecordedSignal_i, \contFilter_i$ respectively,
    \item $\scrT(\disRecordedSignal_i)$ is the $(2N+L-1) \times L$ Toeplitz matrix (built as shown in~\cref{fig:blaster:toeplitz})\marginpar{
        \centering
        \resizebox{\linewidth}{!}{
            \input{figures/blaster/toeplitz.tikz}
            }
            \captionof{figure}{Graphical representation of the construction of $\scrT(x_i)$ from $x_i$}
            \label{fig:blaster:toeplitz}
            }
    associated to a convolution where $2N$ and $L$ respectively denote the microphone and filter signal lengths,
    \item $\bfh = \klist{h_1^\intercal, h_2^\intercal}$ is the concatenation of the two vectorized discrete filters,
    \item and the $\ell_1$ regularization term is used to enforce sparsity in the estimation, which is consistent with the ``train of impulses'' model for the early part of \acp{RIR} (but not for the tail).
\end{itemize}
This type of problem can be seen as an instance of \LASSO/ problem~\citeonly{tibshirani1996regression}, written in the form:
\begin{equation}\label{eq:blaster:lasso}
    \kargmin_{u} \tfrac{1}{2} \kvvbar{v - Au}_2^2 + \lambda\kvvbar{u}_1
    .
\end{equation}
This type of well-known optimization problem are convex and, despite the non-differentiability of the $\ell_1$-norm, they can be easily tackled by standard optimization tool.
Later, in this section, we show how to express~\cref{eq:blaster:xrel_toepl} as a standard \LASSO/ problem.

\mynewline
The accuracy of estimated \acp{RIR} has been subsequently improved using a priori knowledge on the filters.
In particular, the authors of~\citeonly{lin2007blind} have proposed to use non-negativity constraints to increase robustness to noise and avoid trivial solution.
Therefore, let us define a more general formulation for~\cref{eq:blaster:xrel_toepl}, as follows
\begin{equation}\label{eq:blaster:sota}
    \disFilterHat_1, \disFilterHat_2
    =
    \kargmin_{\disFilter_1, \disFilter_2}
    \;
    \scrJ(\disFilter_1, \disFilter_2) + \scrP(\disFilter_1, \disFilter_2)
    \;\text{s.t.}\;
    \scrC(\disFilter_1, \disFilter_2)
\end{equation}
where $\scrJ(\disFilter_1, \disFilter_2) = \tfrac{1}{2} \kvvbar{\scrT(\disRecordedSignal_1) \disFilter_2 - \scrT(\disRecordedSignal_2) \disFilter_1}_2^2$ is the cost function to optimize.
$\scrP(\disFilter_1, \disFilter_2)$ and $\scrC(\disFilter_1, \disFilter_2)$ are respectively a regularization term used to promote sparse solutions and a constrained set.
Thanks to this formulation, current state-of-the-art approaches can be summarized as in the~\cref{tab:blaster:sota}.

\begin{table}[!h]

    \begin{fullwidth}
        \centering
        \small
        \input{tables/blaster/sota.tex}

        \caption{Some state-of-the-art penalties and constraints used in~\cref{eq:blaster:sota}.}
        \label{tab:blaster:sota}
    \end{fullwidth}
\end{table}

\mynewline
The constraint $\disFilter_i[0]=1$ is called an \textit{anchor constraint} and it is used to replace the $\ell_2$-norm while keeping the problem convex.
The non-negativity $\bfh \geq 0$ constraint may not be satisfied due to effects such as measurement process, the filtering in the propagation media or the imperfect frequency response of a microphone.
However, when those effects are common to both channels, they can be viewed as distortions to a common source.
Therefore, the non-negativity assumption seems reasonable for real acoustic environments.
Nevertheless, applications concerning \RooGE/ require just the recovery of lower order reflections, i.e. the sparse portion of the \RIR/.
Likewise works in speech enhancement have proven to work under such assumption, thus proving the effectiveness of this approach, such as in~\citeonly{lin2008blind, yu2011multi}.

\mynewline
On a similar scheme, in~\citeonly{kowalczyk2013blind},~\cref{eq:blaster:xrel_toepl} is solved using an adaptive time-frequency-domain approach while~\citeonly{aissa2008blind} proposes to use the $\ell_p$-norm instead of the $\ell_1$-norm.
Choosing $p < 1$, sparsity is enforced, however the problem become non-convex and ad-hoc optimization technique was proposed.
A successful approach has been presented recently by the authors of~\citeonly{crocco2016estimation}, where the anchor constraint is replaced by an \textit{iterative weighted} $\ell_1$ equality constraint, \ie/, such that at each iteration $z$, $\ktranspose{\bfp^{(z)}}\bfh^{(z)} = 1$.\sidenote{
    Note that when $\bfp^{(z)} = \onesVect$, the constraint returns to the $\ell_1$ penalty.}
In particular, the method is initialized using the solution of \citeonly{lin2007blind} and iterated enforcing sparsity using the solution of the previous problem, that is $\bfp^{(z)} = \hat{\bfh}^{(z-1)}$.
The reader can find a comprehensive review of these methods in~\citeonly{crocco2015room,crocco2016estimation}.

\newthought{The limitation of the discrete-time methods} described above are the followings:
\begin{itemize}
    \item \textit{Basis mismatch}:\marginpar{%
        \centering
        \footnotesize
        \includegraphics[trim={0 0 0 0},clip,width=\linewidth]{blaster/bodyguard.png}
        \captionof{figure}{%
            Schematics of the \textit{bodyguard effect} affecting on-grid approaches.
            This is true only if $\flt$ is non-negative.
        }
        \label{fig:blaster:bodyguard}
    } As explained in~\cref{subsec:estimation:bce}, the filter are not sparse in practice due to the \textit{basis mismatch}.
    This implies that the peaks of the filter do not necessarily correspond to the true echoes and lead to followings drawbacks.
    As these methods operates fundamentally \textit{on-grid}, they return echoes' timings which are integer multiples of the inverse of $\Fs$.
    \item \textit{Bodyguard effect}.
    In addition to affecting the \AER/ performance, on-grid methods may converge slowly to suboptimal solutions.
    In fact, as shown in~\cref{fig:blaster:bodyguard}, instead of estimating the positive peaks at its true location, two smaller ``bodyguard'' peaks are estimated around it instead.
    The estimation procedure may stop at this point returning two wrong peaks.
    Having smaller coefficients, these peaks may not be selected by the subsequent peak picking technique.
    Alternatively, the optimization procedure may continue, alternating tuning the weights of the two ``bodyguards'', without converging to a solution.
    \item \textit{Computational bottleneck}.
    A way to cope with the above limitations is to increase the $\Fs$.
    However this results into a memory and computational bottleneck as several huge (Toeplitz) matrices need to be built, one for each pair of microphones.
    In addition, this leads to the risk that the optimization problem becomes ill-conditioned.
\end{itemize}

\mynewline
In the following section we will present a novel approach that aims at addressing the above limitations.
It is based on a framework proposed for solving \ac{LASSO} problems for continuous variables, hence the name \ac{CD}.
Before, let us show how to express the on-grid \BCE/ problem proposed by~\citeonly{lin2008blind} (See \cref{tab:blaster:sota}) as a standard \LASSO/ problem.

\subsection{From cross-relation to LASSO}
Integrating the sparse penalty and the constraints proposed in \cref{eq:blaster:sota},
the \BSNdef/ problem proposed reads
\begin{equation}\label{eq:blaster:bsn}
    \disFilterHat_1, \disFilterHat_2
    =
    \kargmin_{\disFilter_1, \disFilter_2}
    \;
    \tfrac{1}{2}
    \kvvbar{
        \scrT(\disRecordedSignal_1) \disFilter_2
        -
        \scrT(\disRecordedSignal_2) \disFilter_1
    }_2^2
    + \lambda\kvvbar{\bfh}_1
    \;\text{s.t.}\;
    \begin{cases}
        \bfh \geq 0\\
        h_1[0] = 1
    \end{cases}
    .
\end{equation}
This cross-relation based optimization problem can be rewritten in the \LASSO/ formulation of~\cref{eq:blaster:lasso} as
\begin{equation*}
    u
    =
    \kargmin_{u}
    \;
    \tfrac{1}{2}
    \kvvbar{ v - B u }_2^2
    + \lambda\kvvbar{u}_1
    \quad\text{s.t.}\quad
    u \geq 0
    ,
\end{equation*}
where
\begin{equation*}
    v = T_2e_1,
    \quad
    u =
    \begin{pmatrix}
        h_1[1:] \\
        h_2
    \end{pmatrix},
    \quad
    A =
    \begin{pmatrix}
        -T_2[:, 1:] & T_1
    \end{pmatrix}
    ,
\end{equation*}
where $T_i = \scrT(x_i)$.
Here we used the light, yet common, Python notation for indexing the matrices and vectors.
The matrix $A$ is typically called \textit{dictionary}.


\section{Proposed approach}

The cross-relation identity~\cref{eq:blaster:cross-relation} ensures that the relation
\begin{equation}
    \idealLowPassFilter
    \ast \contRecordedSignal_1
    \ast  \contFilter_2^\star
    =
    \idealLowPassFilter
    \ast \contRecordedSignal_2
    \ast  \contFilter_1^\star
\end{equation}
holds even during the introduced measurement process, hence
\begin{equation}
    \label{eq:blaster:cross-relation-identity-fourier}
    \fourierTrans(\idealLowPassFilter\ast\contRecordedSignal_1) \cdot \fourierTrans \contFilter_2^\star
    =
    \fourierTrans(\idealLowPassFilter\ast\contRecordedSignal_2) \cdot \fourierTrans \contFilter_1^\star
\end{equation}
where $\fourierTrans$ denotes the \FTdef/ described in~\cref{sec:processing:domains}.
\\In contrast with \SIMO/-\BCE/ methods that operates in the time domain, here we propose to use~\cref{eq:blaster:cross-relation-identity-fourier} in a penalized least-square problem.
Such a formulation in the Fourier domain may even be considered as more convenient since the convolution operator is no longer involved.
While the \FT/ of $\contFilter_i^\star$ can be expressed in closed-form (see~\cref{eq:blaster:closed-form-TF-dirac-N} below), the \FT/ of $\idealLowPassFilter\ast\contRecordedSignal_i$ is not available due to the measurement process.
To circumvent this issue, we consider the \DFTdef/ of $\contRecordedSignal_i$:
\begin{equation}
    \label{eq:blaster:approx-TF}
    \fourierTrans(\idealLowPassFilter\ast\contRecordedSignal_i)
    %(\tfrac{f}{F_s})
    \kparen{\tfrac{k}{2N}F_s}
    =
    X_i[k]
\end{equation}
for all integers  $k \in \{0, \ldots, N\}$, where
\begin{equation}
    \label{eq:blaster:dft-Xi}
    \RecordedSignalDFT_i[k] = \sum_{n=0}^{2N-1}
    \disRecordedSignal_i[n]
    \cste^{-\csti2\pi \tfrac{kn}{2N}}
\end{equation}
is the \DFT/ of the real vector $\contRecordedSignal_i$ as defined in~\cref{eq:processing:dft} for positive frequencies only.

\mynewline
Let us define $\paramVec{\tau}$ the following parametric vector of complex exponential
\begin{equation}
    \label{eq:blaster:closed-form-TF-dirac-N}
    \paramVec{\tau} \eqdef
    \left(\cste^{-\csti2\pi\tfrac{k}{2N}F_s \tau}\right)_{0 \leq k \leq N}
    \in\bbC^{N+1}
    ,
\end{equation}
where we consider only the $N$ positive frequencies due to the Hermitian symmetry of the signal spectra in this application.
Then, the Fourier-domain cross-relation of~\cref{eq:blaster:cross-relation-identity-fourier} evaluated at $f = \frac{k}{2N}F_s$ where $k \in \{0,\ldots, N\}$
reads

\begin{equation}
    \label{eq:blaster:cross-relation-approx}
    \sum_{r=0}^{R_2-1} \alpha_2^{(r)} \RecordedSignalDFT_1 \odot \paramVec{\tau_{2}^{(r)}}
    =
    \sum_{r=0}^{R_1-1} \alpha_1^{(r)} \RecordedSignalDFT_2 \odot \paramVec{\tau_{1}^{(r)}}
\end{equation}
where $\odot$ denotes the component-wise Hadamard product.

\mynewline
With the above notation, in the following subsection we will present the \ac{CD} framework for \AER/.
This section is written with the help of the colleague Clement Elvira, co-author of a publication based on this work.

\subsection{Echo localization with continuous dictionaries}
By interpreting the \FT/ of a Dirac as a parametric \textit{atom}, we propose to cast the problem of \RIR/ estimation into the framework of \CD/.
To this aim, let the so-called \emph{parameter set} be
\begin{equation}
    \label{eq:blaster:parameter-set}
    \Theta \eqdef \kintervcc{0}{T} \times \kbrace{1, 2}
    ,
\end{equation}
where $T$ is the length (in time) of the filter.
Then, the two desired filters  $\contFilter_1^\star$, $\contFilter_2^\star$ given by~\cref{eq:blaster:def_filter_star} can be uniquely represented by the following discrete measure over $\Theta$
\begin{equation}
    \label{eq:blaster:representation_filter_measure}
    \mu^\star = \sum_{i=1}^{2} \sum_{r=0}^{R_{i}-1} \alpha_{i}^{(r)} \delta_{(\tau^{(r)}, i)}.
\end{equation}
where $\delta_{(\tau^{(r)}, i)}$ denotes the Dirac measure which is different from the Dirac function used when modeling the \acp{RIR}.
The need of defining a measure over the parameter set $\Theta$ makes easier the parametrization of the problem in the context of \CD/.
For instance, it is possible to better define operations which are used in the algorithms and in the literature to solve this type of problems.
\\Moreover, the rationale behind~\cref{eq:blaster:parameter-set} and~\cref{eq:blaster:representation_filter_measure} is as follows.
A couple of filters is now represented by a single stream of Diracs, where we have considered an augmented variable $i$ indicating to which filter the spike belongs.
For instance, a Dirac measure at $(\tau, 1)$ indicates that the filter 1 contains a Dirac at $\tau$.

\mynewline
The set $\posDisRadonMeasure$ of all unsigned and discrete Radon measures over $\Theta$ (\ie/, the set of all couples of  filters) is equipped with the total-variation norm (TV-norm) $\normTV{\mu}$
\sidenote{See~\citeonly{rudin1987real} for a rigorous construction of measures set and the TV-norm.}.
We now define the \emph{linear} observation operator $\kfuncdef{\opObs}{\posDisRadonMeasure}{\bbC^{N+1}}$, which is such that
\begin{equation}
    \opObs\delta_{(\tau, i)}
    =
    \begin{cases}
        - \RecordedSignalDFT_1 \odot \paramVec{\tau}  &\text{ if } i=1 \\
        + \RecordedSignalDFT_2 \odot \paramVec{\tau}  &\text{ if } i=2.
    \end{cases}
    \qquad \forall(\tau,i)\in\Theta.
\end{equation}

\mynewline
Therefore, by the linearity of the observation operator $\opObs$, the relation~\cref{eq:blaster:cross-relation-approx} can be rewritten as
\begin{equation}
    \label{eq:blaster:cross-relation-measure}
    \opObs\mu^\star = \zeroVect_{N+1}
    ,
\end{equation}
where $\zeroVect_{N+1}$ is a $N+1$-length vector of zeros.
\\Before continuing our exposition, we note that the anchor constraint can be written in a more convenient way.
Indeed, the constraint $\mu(\{(0, 1)\})=1$ ensures the existence of a Dirac at $0$ in the filter $1$.
Then, the targeted filter reads
\begin{equation}
    \mu^\star = \delta_{(0, 1)} + \bar{\mu}^\star
\end{equation}
where $\bar{\mu}^\star$ is a (finite) discrete measure verifying  $\bar{\mu}^\star\kparen{\{(0, 1)\}} = 0$.
\\Denoting $y\eqdef-\opObs\delta_{(0, 1)}\in\bbC^{N+1}$, the relation~\cref{eq:blaster:cross-relation-measure} becomes
\begin{equation}
    \label{eq:blaster:cross-relation-measure-and-obs}
    \opObs\bar{\mu}^\star = y
    .
\end{equation}
For the sake of clarity, we use these conventions hereafter and omit the bar over $\mu$.
Now, following~\citeonly{de2012exact,candes2014towards}, one can expect to recover the desired filter $\mu^\star$ by solving
\begin{equation}
    \stepcounter{equation}
    \tag{\theequation-$\calP^0_\mathtt{TV}$}
    \label{eq:blaster:TV-BP}
    \widehat{\mu}
    =
    \kargmin_{\posDisRadonMeasure}
    \;
    \normTV{
        \mu
    }
    \quad
    \text{s.t.}
    \quad
    \begin{cases}
        \opObs\mu
        = y \\
        \mu(\{(0, 1)\}) = 0.
    \end{cases}
\end{equation}
Note that~\eqref{eq:blaster:TV-BP} has to be interpreted as a natural extension of the well-known \emph{basis pursuit} problem to the continuous setting.
Indeed, for \emph{any} finite discrete measure $\mu = \sum_{r=0}^{R-1} \alpha^{(r)}\delta_{(\tau^{(r)}, i)}$, the TV-norm of $\mu$ returns to the $\ell_1$-norm of the coefficients, \ie/, $\kvvbar{\mu}_{\mathtt{TV}} = \sum_{\idxEch=0}^{\numEchs-1} \kvbar{\alpha^{(r)}}$.

\mynewline
Finally,~\cref{eq:blaster:cross-relation-measure-and-obs} can be exploited to take into account noise during the measurement process (\ie/,  $n_i\neq0$ in~\cref{eq:blaster:recordedSignal}), as well as approximation errors  (see~\cref{eq:blaster:approx-TF}-\cref{eq:blaster:cross-relation-approx}).
In that case, the first equality constraint in~\eqref{eq:blaster:TV-BP} is relaxed, leading to the so-called \BLASSO/ problem
\begin{equation}
    \stepcounter{equation}
    \tag{\theequation-$\calP^\lambda_\mathtt{TV}$}
    \label{eq:blaster:TV-BLASSO}
    \begin{split}
    \widehat{\mu}
    =
    \kargmin_{\mu \in\posDisRadonMeasure}
    \;
    \tfrac{1}{2} \kvvbar{
        y - \opObs\mu
    }_2^2
    +
    \lambda\normTV{
        \mu
    }
    \quad
    \text{s.t.}
    \quad
    \mu(\{(0, 1)\}) = 0
    .
    \end{split}
\end{equation}
We emphasize that although continuous Radon measures may potentially be admissible, the minimizers of~\cref{eq:blaster:TV-BLASSO} are \emph{guaranteed} to be streams of Dirac\textit{s}~\citeonly[Theorem~4.2]{bredies2020sparsity}.
In addition, although problem~\cref{eq:blaster:TV-BLASSO} seems to depend on some regularization parameter $\lambda$, we describe in~\cref{sec:blaster:lambda} a procedure to automatically tune it to recover a desired number of spikes.
Finally, note that the problem in~\cref{eq:blaster:TV-BLASSO} is convex with linear constraints over the parameter set $\Theta$.
Therefore, theoretically, the problem can be solved exactly.
However, optimizing over the infinite-dimensional space of measures is not possible, and hence non-convex optimization with respect to the measures \textit{parameters} is performed instead.
% However, in practice, optimization over space of measures, still complicated because many steps can only be done up to a prescribed precision.
% 1) you define atome function (14) without the dirac measure
% ex: a: tau -> a(tau)
% 2) you define the desired filter as \sum_{c_{i, r}} a(\tau_{i, r})
% 3) The How?
% 4) existing work of antoine and Helena
% fix the number of echoes
% say c_1... \tau_1... = \argmin someting
% frawback complicated, non convex and so
% 5) idea: rephrease is a convex formulation
% -> convenient framework is set of measurexs of theta
% Convex in the measure
% theoretically, we have algorithm to solve the  problkem exactly
% But in practice, optimization over space of measures, still complicated
% because many steps can only be done up to a prescribedf precision
% (unkike classical convex optimization)
% step 7 and 15

\subsection{From LASSO to BLASSO}
In order to better understand the proposed approach based on the \BLASSO/ algorithm, we can present it in light of the \LASSO/ formulation.
\begin{gather*}
    \kargmin_u \tfrac{1}{2} \kvvbar{v - A u}_2^2 + \lambda \kvvbar{u}_1 \;\text{s.t.}\; u \geq 0\\
    \downarrow\\
    \kargmin_u \tfrac{1}{2} \kvvbar{y - \opObs\mu}_2^2 + \lambda \normTV{\mu} \;\text{s.t.}\; \mu \in\posDisRadonMeasure\\
\end{gather*}
Now, some parallelism can be envisioned:
\begin{itemize}
    \item\textit{From dictionary to operator}:
    The matrix $A$ is typically referred to as \textit{dictionaries}.
    Then selecting the $l$-th column of the dictionaries, \ie/ $Ae_l$, means selecting an echo at location $l$-th \wrt/ the vector $u = \bfh[1:]$.
    In the context of \CD/, the dictionary is translated into the operator $\opObs$ thanks to the closed-form of the atom based on the Fourier theory.
    Therefore, $\opObs(\delta_\tau)$ can be seen as the selection of an echo at location $\tau \in [0, T]$~ms.
    \item\textit{Solution}:
    The \LASSO/-like approach promotes a solution $u = \bfh[1:]$ which is sparse and non-negative vector.
    In the \BLASSO/, this is translated assuming the channels being spare non-negative measures, \ie/, $\mu = \sum_r \alpha^{(r)} \delta(t - \tau^{(r)})$.
    \item\textit{Sparsity}: while in the initial case, the sparsity is enforced by the $\ell_1$-norm, in the second case it is pursued with the TV-norm.
    \item\textit{Solver}: the former optimization problem can be solved with standard \LASSO/ solvers, while for the latter a gradient-descent algorithm is used.
\end{itemize}

\marginpar{
    \vspace{-35\baselineskip}
    \centering
    \includegraphics[width=0.5\linewidth]{blaster/echo0.png}\\
    $\downarrow$\\
    \includegraphics[width=0.5\linewidth]{blaster/echo1.png}\\
    $\downarrow$\\
    \includegraphics[width=0.5\linewidth]{blaster/echo2.png}\\
    $\downarrow$\\
    \includegraphics[width=0.5\linewidth]{blaster/echo3.png}\\
    $\downarrow$\\
    \includegraphics[width=0.5\linewidth]{blaster/echo4.png}\\
    $\downarrow$\\
    \includegraphics[width=0.5\linewidth]{blaster/echo5.png}
    \captionof{figure}{
        Illustration of the sliding Frank-Wolfe algorithm proposed in~\citeonly{denoyelle2019sliding} in \BLASTER/.
    }
    \label{fig:blaster:sfw}

}

\subsection{The resulting algorithm}
The algorithm used to solve~\cref{eq:blaster:TV-BLASSO} is an of instance the sliding Frank-Wolfe algorithm proposed in~\citeonly{denoyelle2019sliding} to solve~\cref{eq:blaster:TV-BLASSO}.
Detailed descriptions of the steps of the algorithm are given in~\citeonly[Supplementary Material]{di2020blaster}.
In a nutshell, the algorithm iterates over the following steps until a condition on the cost function is met.
\begin{enumerate}
    \item \textit{Anchor constraint}.
    At first the anchor constraint in added arbitrarily on one of the two filters. This is used to initialize the two filters.
    \item \textit{\textit{Local} cost based on Cross-relation}.
    For both the filters, a local cost-function derived from the cross-relation for both the filters is computed.
    At this step either the initialization or a previously found solution is used.
    \item \textit{Find the maximizer}.
    A new candidate echo's location is found as maximizer among the two local cost functions of the previous step.
    \item \textit{Update the amplitudes}.
    By solving a non-negative \LASSO/ problem, all the echo's amplitude coefficients estimated until this point are updated.
    \item \textit{Joint refinement}.
    The position and the coefficient of the current solution are jointly refined to ease numeric resolution using the original cost function.
    \item \textit{Current solution and repeat}.
    The algorithm stops as soon as an iterate satisfies the first order optimality condition associated to the convex problem.
    Otherwise, the algorithm iterates from step 2. using the current solution as input.
\end{enumerate}
These steps are illustrated in~\cref{fig:blaster:sfw}.
% \begin{figure}[h]
%     \begin{fullwidth}
%     \centering
%     \subfloat[echo0][Anchor]{
%         \includegraphics[width=0.13\linewidth]{blaster/echo0.png}
%         \label{fig:blaster:echo0}}
%     \hfill
%     \subfloat[echo1][Local evaluation]{
%         \includegraphics[width=0.13\linewidth]{blaster/echo1.png}
%         \label{fig:blaster:echo1}}
%     \hfill
%     \subfloat[echo2][Maximizer]{
%         \includegraphics[width=0.13\linewidth]{blaster/echo2.png}
%         \label{fig:blaster:echo2}}
%     \\
%     \subfloat[echo3][Update echoes' amplitudes]{
%         \includegraphics[width=0.13\linewidth]{blaster/echo3.png}
%         \label{fig:blaster:echo3}}
%     \hfill
%     \subfloat[echo4][Joint refinement]{
%         \includegraphics[width=0.13\linewidth]{blaster/echo4.png}
%         \label{fig:blaster:echo4}}
%     \hfill
%     \subfloat[echo5][Current solution]{
%         \includegraphics[width=0.13\linewidth]{blaster/echo5.png}
%         \label{fig:blaster:echo5}}
%     \hfill
%     \end{fullwidth}
% \end{figure}

\subsection{Homotopic path for $\lambda$ estimation}\label{sec:blaster:lambda}
Existing works, as well as the proposed one, rely on of the regularization parameter $\lambda$ to weight the sparsity penalty.
However, this becomes an hyperparameter that needs to be carefully tuned according to the input data.
Instead, we propose to compute a \textit{path of solutions} to automatically estimate it in~\cref{eq:blaster:TV-BLASSO}.
In the context of sparse optimization this technique is also referred to as \textit{homotopic path}.
More precisely, let $\lambda_{\max}$ be the smallest value of $\lambda$ such that the null measure is the solution to~\cref{eq:blaster:TV-BLASSO}.
It can be shown that $\lambda_{\max}$ is upper bounded by $\max_{\theta\in\Theta} \kvbar{y^\intercal\opObs\delta_\theta}$.
Starting from $z=1$ and the empty filter, we consider a sequential implementation where the solution of~\cref{eq:blaster:TV-BLASSO} is computed for $\lambda^{(z)}= 10^{-0.05z}\lambda_{\max}$ until the desired number of spikes is found in each channel when incrementing $z$.
For each $\lambda^{(z)}$, we search for a solution of~\cref{eq:blaster:TV-BLASSO} with the solution obtained for $\lambda^{(z-1)}$ as a warm start.

\section{Experiments}\label{sec:blaster:exp}
The proposed method (\BLASTER/) is compared against the non-negative $\ell_1$-norm method (\algoBsn) of~\citeonly{lin2007blind} and the iterative $\ell_1$-norm approach (\algoCrocco) described in~\citeonly{crocco2016estimation}.\sidenote{
    Reference implementations for \algoCrocco{} and \algoBsn{} were kindly provided by the authors of~\citeonly{crocco2016estimation}.
}
The problem is formulated as estimating the time locations of the first $\numEchs=7$ strongest components of the RIRs for 2 microphones listening to a single sound source in a shoebox room. It corresponds to the challenging task of estimating first-order early reflections.
The robustness of the methods is tested against different levels of noise (SNR) and reverberation time (\RT{}).

\mynewline
The quality of AER estimation is assessed in terms of precision\sidenote{
    Since only $K$ time locations are considered in both the ground truth and the estimation, precision and recall are equal.}
in percentage as in the literature of onset detection~\citeonly{bock2012evaluating} and the \RMSEtxt/ in samples.
Both metrics evaluate only the \textit{matched} peaks, where a \textit{match} is defined as being within a small window $\thr$ of a reference delay.
These two metrics are similar to the ones used in~\citeonly{crocco2015room}.

\mynewline
For this purpose we created three synthetic datasets of $1000$ observations each, which are summarized in~\cref{tab:blaster:datasets}.
\begin{table}[ht]
    \begin{sidecaption}[]{
        Summary of the dataset used for evaluation. \epsdice[black]{3} and \epsdice{5} stands for randomly sampled from a continuous and discrete set of values, respectively, with uniform law.
    }[tab:blaster:datasets]
    \centering
    \small
    \input{tables/blaster/datasets.tex}
    \end{sidecaption}
\end{table}
\\\dsetValid{} is used for tuning the hyperparameter $\lambda$ and the peak-picking parameters for \algoCrocco{} and \algoBsn{} using \RT{} and SNR randomly drawn from $\mathcal{U}[0, 1]$ (sec) and $\mathcal{U}[0, 20]$ (dB) respectively; \dsetSNR{} features SNR value uniformly sampled in $[0, 6, 14, 20, \infty]$ while the \RT{} is kept fixed to $400$ ms; akin the \dsetRT{} is built sampling \RT{} value uniformly in $[200, 400, 600, 800, 1000]$ ms keeping SNR to 20 dB.
Moreover, while for \dsetValid{} broadband signals (white noise) are used as the source, for \dsetSNR{} and \dsetRT{} speech utterances from the TIMIT dataset~\citeonly{garofolo1993timit} are also included.
The signal duration is kept fixed to 1 s with sampling frequency $\Fs = 16$ kHz.
For a given \RT{} value and room with random dimensions, a unique absorption coefficient is assigned to all surfaces based on Sabine's formula (\cref{eq:processing:sabine}).
Then, the two microphones and the source are randomly positioned inside the room.
The parameters of the audio scene are then passed as input to the \pyroomacoustics{} simulator~\citeonly{scheibler2018pyroomacoustics}, which returns the corresponding \acp{RIR} as well as the \textit{off-grid} echo delays and attenuation coefficients computed with the \ISMdef/~\citeonly{allen1979image}.
Note that when generating the data, no samples have been pruned to match any minimal separation condition.
To generate the microphone signals, an over-sampled version of the source signal is convolved with ideal \acp{RIR} at high frequency ($\Fs=1024$ kHz) made up of on-grid Dirac\textit{s}.
The results are later resampled to meet the original $\Fs$ and Gaussian white noise is added to meet the given SNR value.

\mynewline
Finally, as described throughout~\cref{ch:estimation}, \algoCrocco{} and \algoBsn{} uses tuned peak picking step to identity the echoes.
Here the same peak picking technique provided with reference implementation of these methods was used and tuned on a small validation set.


\newthought{Quantitative results} are reported in ~\cref{fig:error_precision_snr_rt}, ~\cref{fig:error_precision_kecho} and ~\cref{tab:error_precision_thr}.
Here, for both RMSE and precision and for both broadband and speech signal, the metrics are displayed against the dataset parameters.
We observe that \algoBsn{} performs worst in all tested conditions, possibly due to its strong reliance on the peak picking step.
For $\numEchs=7$ or higher, \algoBraire{} yields similar or slightly worse performance than \algoCrocco{} for the considered noise and reverberation levels, with decreasing performance for both as these levels increase.
Using speech rather than broadband signals also yields worse results for all methods.
However, the echo timing RMSE is significantly smaller using \algoBraire{} due to its off-grid advantage.
We also note that \algoBraire{} significantly outperforms \algoCrocco{} on the task of recovering $\numEchs=2$ echoes.
As showed in Tab.~\ref{tab:error_precision_thr}, in mild conditions ($\RT = 200$~ms, $\mathtt{SNR} = 20$~dB), up to 68\% of echoes can be retrieved by \algoBraire{} with errors lower than a quarter of sample in that case.
This is promising since the practical advantage of knowing the timings of two echoes per channel has been demonstrated in~\citeonly{di2019mirage} (See~\cref{ch:mirage}), and in~\citeonly{scheibler2018separake} (See~\cref{ch:separake}).

\begin{figure}[ht]
    \centering
    \begin{fullwidth}
        \includegraphics[width=.49\textwidth]{figures/blaster/e_k-7_thr-2_bns_crocco_blaster.pdf}
        \includegraphics[width=.49\textwidth]{figures/blaster/p_k-7_thr-2_bns_crocco_blaster.pdf}
        \caption{%
            \label{fig:error_precision_snr_rt}
            Mean error (left) and precision (right) versus SNR level (top) and \RT{} level (bottom) using broadband and speech signals for the task of recovering $\numEchs=7$ echoes. A threshold of $\tau_{\textrm{max}}=2$ samples is used to compute the precision.
            Error bands denotes 95\% confidence intervals.
        }

    \end{fullwidth}
\end{figure}

\begin{table}[ht]
    \begin{sidecaption}[]{
        Precision for different threshold $\thr$ in samples for the recovery of $R = 2$ and $7$ echoes, $\RT = 200$~ms and $\SNR = 20$~dB.
    }[tab:error_precision_thr]
    \centering
    \footnotesize
    \input{tables/blaster/different_thr.tex}
    \end{sidecaption}
\end{table}

\begin{figure}[t!]
    \begin{sidecaption}[]{
        Precision versus number of echoes $R$ to be retrieved for broadband (left) and speech (right) signals with \RT{} = $400$ ms and SNR = 20 dB.
        Error bands denotes 95\% confidence intervals.
    }[fig:error_precision_kecho]
    \centering
    \includegraphics[width=\linewidth]{figures/blaster/p_k-7_thr-2_bns_crocco_blaster-peak_withRechoes.pdf}
    \end{sidecaption}
\end{figure}

\section{Conclusion}
In this chapter we presented a novel knowledge-driven blind, off-grid echo retrieval method, based on the framework of continuous dictionaries.
The particular ``knowledge'' we used is the echo model for the early part of the \acp{RIR}.
The main motivation behind this approach is to overcome the pathological limitation of classical methods for \ac{BCE}, discussed in the previous chapter.
Despite an heavy mathematical formulation, it can seen as as the continuous extension of a \LASSO/ problem used for addressing \ac{BCE}.
Comparisons with state-of-the-art approaches on various noise and reverberation conditions show that this method performs best when the number of echoes to retrieve is small.
Future works will include many exciting directions, such as:
\begin{itemize}
    \item extending the framework to multichannel recordings using the Multichannel cross-relation, as already envisioned by the related works~\citeonly{crocco2015room,lin2008blind};
    \item compare this approach with other off-grid \AER/ methods  ~\citeonly[Chapter 6]{peic2020sparse};
    \item adapt this approach to deal with \ReTF/ which allow for source-independent acoustic features (See~\cref{ch:dechorateapp});
    \item use deep learning approaches to estimate the level of sparsity (\aka/ number of the most relevant echoes) in the \acp{RIR};
    \item validate the approach on real-world recordings, such as the one provided by the \ac{DECHORATE} dataset (See~\cref{ch:dechorate}).\qed
\end{itemize}