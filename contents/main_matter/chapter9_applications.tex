\chapter{Application of Acoustic Echoes}\label{chap:application}

\newthought{Synopsis} \blindtext

\section{Auditory Scene Analysis}


\subsection{Literature review: an acoustic perspective}
Bibliography with respect to sound propagation
\begin{itemize}
    \item Ignored
    \item Anechoic Phat
    \item Fully modeled
    \item Early echoes
\end{itemize}

\subsection{Literature review: an algorithmic perspective}\cite{subsec:application:algos}
Bibliography with respect to learning and knowledge approaches



%% problems %%
\newthoughtpar{Separation \vs/ Enhancement}

%% models %%
\newthoughtpar{end2end \vs/ 2step}
end2end: from data to (feature to) target
\\2-step: (from data to features) + features to target

\newthoughtpar{Knowledge-based \vs/ Learning-based}
\begin{itemize}
    \item Bottom-up vs Top-down information processing
    \item Knowledge-based: specialized signal processing and mathematical algorithms informed by knowledge;
    \item Learning-based: machine learning usually trained in supervised fashion.
\end{itemize}

\newthoughtpar{Supervised \vs/ Unsupervised}
\newthoughtpar{Machine Learning \vs/ Deep Learning}


\section{Problem Formulation}
Given the narrowband \STFT/ signal model presented is~\cref{subsec:processing:model:stft}, the signals captured by $\numMics$ microphone listening to a single sound source ($\numSrcs=1$) in a noisy reverberant room, reads:
\begin{equation}
    \MICS[k,l] = \FLTS[k] \SRC[k, l]+ \NSES[k,l]
    ,
\end{equation}


\newthought{Sound Source Separation}

\newthought{Spatial Filtering}

\newthought{Localization}



\section{Separation, Spatial Filtering and Localization}

\subsection{Speech Source Separation}
Audio source separation refers to the process of extracting acoustic signals from mixtures featuring target and interfering sounds.
The ability of focusing on a selected source only, while filtering out the rest, is known as \textit{the cocktail party effect}~\citeonly{cherry1953cocktail, bee2008cocktail}
The scenario where no prior knowledge is available about both the sources and the mixing process, is usually referred to as \textit{blind sound separation}.
When it is applied to approximate human hearing, such as using only stereophonic mixture and considering the human auditory system, it is known as \CASAdef/.

[Remaggi thesis]
Two of the mostly investigated areas study either musical or speech recordings [Vincent et al., 2012].
Although music source separation represents a key part of the audio community [Ewert et al., 2014], the focus of this thesis is on speech source separation.
This is of interest for several audio applications, such as: speech enhancement [Mohammadiha et al., 2013], crosstalk cancellation [Akeroyd et al., 2007], hearing aids [Healy et al., 2013], and automatic speech recognition [Li et al., 2014]

Echoes have been used previously to enhance various audio processing tasks.

It was shown that they improve indoor beamforming \citeonly{Dokmanic:2015dr, Scheibler:2015ii, RobinThesis},
aid in sound source localization \citeonly{Ribeiro:2010uj},
and enable low-resource microphone array self-localization \citeonly{Dokmanic:2016gu}.

[Remaggi thesis]
During the last twenty years, speech separation has gained quite of attention. Some of the proposed methods achieved source separation exploiting the availability of a single microphone [Jang and Lee, 2003, Radfar and Dansereau, 2007, Schmidt and Olsson, 2006]. However, they were limited by the amount of information utilised. Therefore, other methods attempted the separation process by employing multichannel microphone arrays. These methods are classically categorised into three main groups, depending on the type of approach undertaken [Vincent et al., 2012]: the beamformers [Araki et al., 2003, Coleman et al., 2015a, VanVeen and Buckley, 1988]; the independent component analysis (ICA) based [Bell and Sejnowski, 1995, Cardoso, 1998, Makino et al., 2007]; the time-frequency (TF) mask based [Alinaghi et al., 2014, Deleforge et al., 2015, Mandel et al., 2010, Sawada et al., 2011, Yilmaz and Rickard, 2004]. A visualisation of these three

\subsection{Speech Source Localization}
\subsection{Spatial Filtering}
Beamformers combines the channels of multiple microphones in order to achieve spatial selectivity, suppressing noise, interferences and reverberation~\citeonly{VanTrees2004Optimum}.

\subsection{Room Geometry Estimation}